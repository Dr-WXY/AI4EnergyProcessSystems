{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StudentAdmissions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engrsmukhtar/AI4EnergyProcessSystems/blob/AI4EPS-1/AI%20Models/Model%201/rankmod/backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ifF0gWwxQxrX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicting Student Admissions with Neural Networks\n",
        "In this notebook, we predict student admissions to graduate school at UCLA based on three pieces of data:\n",
        "- GRE Scores (Test)\n",
        "- GPA Scores (Grades)\n",
        "- Class rank (1-4)\n",
        "\n",
        "The dataset originally came from here: http://www.ats.ucla.edu/\n",
        "\n",
        "## Loading the data\n",
        "To load the data and format it nicely, we will use two very useful packages called Pandas and Numpy. You can read on the documentation here:\n",
        "- https://pandas.pydata.org/pandas-docs/stable/\n",
        "- https://docs.scipy.org/"
      ]
    },
    {
      "metadata": {
        "id": "MsQ9Um9wQxrb",
        "colab_type": "code",
        "outputId": "5cb2744a-0aec-40c1-bd2a-a5f0dc423d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Importing pandas and numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the csv file into a pandas DataFrame\n",
        "url = \"https://raw.githubusercontent.com/engrsmukhtar/AI4EnergyProcessSystems/AI4EPS-1/AI%20Models/Model%201/student-admissions/Calciner%20-%20Duration-Temperature-CO2-CC.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Printing out the first 10 rows of our data\n",
        "data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>temperature</th>\n",
              "      <th>co2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>630.36</td>\n",
              "      <td>0.398463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.00</td>\n",
              "      <td>632.75</td>\n",
              "      <td>0.406479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.00</td>\n",
              "      <td>634.72</td>\n",
              "      <td>0.372648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.00</td>\n",
              "      <td>636.50</td>\n",
              "      <td>0.358011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.00</td>\n",
              "      <td>638.22</td>\n",
              "      <td>0.368520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.00</td>\n",
              "      <td>640.87</td>\n",
              "      <td>0.390545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.00</td>\n",
              "      <td>646.25</td>\n",
              "      <td>0.461572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.00</td>\n",
              "      <td>661.58</td>\n",
              "      <td>0.842583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.01</td>\n",
              "      <td>688.88</td>\n",
              "      <td>2.714227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.01</td>\n",
              "      <td>711.10</td>\n",
              "      <td>4.844138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration  temperature       co2\n",
              "0      0.00       630.36  0.398463\n",
              "1      1.00       632.75  0.406479\n",
              "2      2.00       634.72  0.372648\n",
              "3      3.00       636.50  0.358011\n",
              "4      4.00       638.22  0.368520\n",
              "5      5.00       640.87  0.390545\n",
              "6      6.00       646.25  0.461572\n",
              "7      7.00       661.58  0.842583\n",
              "8      8.01       688.88  2.714227\n",
              "9      9.01       711.10  4.844138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "IID-Zy_TQxrp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting the data\n",
        "\n",
        "First let's make a plot of our data to see how it looks. In order to have a 2D plot, let's ingore the rank."
      ]
    },
    {
      "metadata": {
        "id": "CaQ4xHM-Qxrs",
        "colab_type": "code",
        "outputId": "ae6d6171-7eaf-4a9b-c965-6459729d2bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "# Importing matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Function to help us plot\n",
        "def plot_points(data):\n",
        "    X = np.array(data[[\"duration\",\"temperature\"]])\n",
        "    y = np.array(data[\"co2\"])\n",
        "    admitted = X[np.argwhere(y<=1.0)]\n",
        "    rejected = X[np.argwhere(y>1.0)]\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
        "    plt.xlabel('Test (duration)')\n",
        "    plt.ylabel('Grades (temperature)')\n",
        "    \n",
        "# Plotting the points\n",
        "plot_points(data)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAELCAYAAAA7h+qnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xaayfoliQxr7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Roughly, it looks like the students with high scores in the grades and test passed, while the ones with low scores didn't, but the data is not as nicely separable as we hoped it would. Maybe it would help to take the rank into account? Let's make 4 plots, each one for each rank."
      ]
    },
    {
      "metadata": {
        "id": "bycw82VkQxsF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Separating the ranks\n",
        "data_rank1 = data[data[\"rank\"]==1]\n",
        "data_rank2 = data[data[\"rank\"]==2]\n",
        "data_rank3 = data[data[\"rank\"]==3]\n",
        "data_rank4 = data[data[\"rank\"]==4]\n",
        "\n",
        "# Plotting the graphs\n",
        "plot_points(data_rank1)\n",
        "plt.title(\"Rank 1\")\n",
        "plt.show()\n",
        "plot_points(data_rank2)\n",
        "plt.title(\"Rank 2\")\n",
        "plt.show()\n",
        "plot_points(data_rank3)\n",
        "plt.title(\"Rank 3\")\n",
        "plt.show()\n",
        "plot_points(data_rank4)\n",
        "plt.title(\"Rank 4\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCn8eeEjQxsJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This looks more promising, as it seems that the lower the rank, the higher the acceptance rate. Let's use the rank as one of our inputs. In order to do this, we should one-hot encode it.\n",
        "\n",
        "## TODO: One-hot encoding the rank\n",
        "Use the `get_dummies` function in pandas in order to one-hot encode the data.\n",
        "\n",
        "Hint: To drop a column, it's suggested that you use `one_hot_data`[.drop( )](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)."
      ]
    },
    {
      "metadata": {
        "id": "AmJfRKOWQxsK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## One solution\n",
        "# TODO:  Make dummy variables for rank and concat existing columns\n",
        "one_hot_data = pd.concat([data, pd.get_dummies(data['rank'], prefix='rank')], axis=1)\n",
        "\n",
        "# Drop the previous rank column\n",
        "one_hot_data = one_hot_data.drop('rank', axis=1)\n",
        "\n",
        "# Print the first 10 rows of our data\n",
        "one_hot_data[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NujWYs8fQxsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO: Scaling the data\n",
        "The next step is to scale the data. We notice that the range for grades is 1.0-4.0, whereas the range for test scores is roughly 200-800, which is much larger. This means our data is skewed, and that makes it hard for a neural network to handle. Let's fit our two features into a range of 0-1, by dividing the grades by 4.0, and the test score by 800."
      ]
    },
    {
      "metadata": {
        "id": "7U0jU_DyQxsO",
        "colab_type": "code",
        "outputId": "fedc55da-15d3-4070-871b-57d185fdb29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Making a copy of our data\n",
        "# processed_data = one_hot_data[:]\n",
        "processed_data = pd.concat([data])\n",
        "\n",
        "# TODO: Scale the columns\n",
        "processed_data['duration'] = data['duration']/122.15 #processed_data['duration']/800\n",
        "processed_data['temperature'] = data['temperature']/886.54\n",
        "processed_data['co2'] = data['co2']/37.046161\n",
        "processed_data[:10]\n",
        "\n",
        "# Printing the first 10 rows of our procesed data\n",
        "processed_data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>temperature</th>\n",
              "      <th>co2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.711034</td>\n",
              "      <td>0.010756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008187</td>\n",
              "      <td>0.713730</td>\n",
              "      <td>0.010972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.715952</td>\n",
              "      <td>0.010059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024560</td>\n",
              "      <td>0.717960</td>\n",
              "      <td>0.009664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.032747</td>\n",
              "      <td>0.719900</td>\n",
              "      <td>0.009948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.040933</td>\n",
              "      <td>0.722889</td>\n",
              "      <td>0.010542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.049120</td>\n",
              "      <td>0.728958</td>\n",
              "      <td>0.012459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.057307</td>\n",
              "      <td>0.746249</td>\n",
              "      <td>0.022744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.065575</td>\n",
              "      <td>0.777043</td>\n",
              "      <td>0.073266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.073762</td>\n",
              "      <td>0.802107</td>\n",
              "      <td>0.130760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration  temperature       co2\n",
              "0  0.000000     0.711034  0.010756\n",
              "1  0.008187     0.713730  0.010972\n",
              "2  0.016373     0.715952  0.010059\n",
              "3  0.024560     0.717960  0.009664\n",
              "4  0.032747     0.719900  0.009948\n",
              "5  0.040933     0.722889  0.010542\n",
              "6  0.049120     0.728958  0.012459\n",
              "7  0.057307     0.746249  0.022744\n",
              "8  0.065575     0.777043  0.073266\n",
              "9  0.073762     0.802107  0.130760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "_AdtR66zQxsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into Training and Testing"
      ]
    },
    {
      "metadata": {
        "id": "Kw7Lr4V5QxsT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to test our algorithm, we'll split the data into a Training and a Testing set. The size of the testing set will be 10% of the total data."
      ]
    },
    {
      "metadata": {
        "id": "GAtJqgOxQxsV",
        "colab_type": "code",
        "outputId": "02c9a29b-6cce-4ac6-9fa8-269b15ead569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
        "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
        "\n",
        "print(\"Number of training samples is\", len(train_data))\n",
        "print(\"Number of testing samples is\", len(test_data))\n",
        "print(train_data[:10])\n",
        "print(test_data[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples is 110\n",
            "Number of testing samples is 13\n",
            "    duration  temperature       co2\n",
            "15  0.122964     0.845489  0.211695\n",
            "79  0.647564     0.870711  0.228901\n",
            "67  0.549161     0.801284  0.049922\n",
            "95  0.778715     0.974530  0.949445\n",
            "53  0.434466     0.789835  0.034284\n",
            "33  0.270487     0.783507  0.026709\n",
            "43  0.352436     0.775272  0.024187\n",
            "99  0.811461     0.978817  0.990285\n",
            "39  0.319689     0.773005  0.018846\n",
            "97  0.795088     0.976786  0.970191\n",
            "    duration  temperature       co2\n",
            "3   0.024560     0.717960  0.009664\n",
            "23  0.188539     0.876464  0.201693\n",
            "28  0.229472     0.789801  0.185091\n",
            "36  0.295047     0.773614  0.018387\n",
            "45  0.368809     0.778803  0.027170\n",
            "57  0.467212     0.794019  0.036959\n",
            "71  0.581989     0.864394  0.340414\n",
            "90  0.737700     0.958614  0.601136\n",
            "92  0.754155     0.968811  0.820275\n",
            "93  0.762341     0.971406  0.888242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PT4POZ0DQxsb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into features and targets (labels)\n",
        "Now, as a final step before the training, we'll split the data into features (X) and targets (y)."
      ]
    },
    {
      "metadata": {
        "id": "lhV_vfgEQxsd",
        "colab_type": "code",
        "outputId": "af24db9a-77fb-400d-d4be-ff45b079f182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "features = train_data.drop('co2', axis=1)\n",
        "targets = train_data['co2']\n",
        "features_test = test_data.drop('co2', axis=1)\n",
        "targets_test = test_data['co2']\n",
        "\n",
        "print(features[:10])\n",
        "print(targets[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    duration  temperature\n",
            "15  0.122964     0.845489\n",
            "79  0.647564     0.870711\n",
            "67  0.549161     0.801284\n",
            "95  0.778715     0.974530\n",
            "53  0.434466     0.789835\n",
            "33  0.270487     0.783507\n",
            "43  0.352436     0.775272\n",
            "99  0.811461     0.978817\n",
            "39  0.319689     0.773005\n",
            "97  0.795088     0.976786\n",
            "15    0.211695\n",
            "79    0.228901\n",
            "67    0.049922\n",
            "95    0.949445\n",
            "53    0.034284\n",
            "33    0.026709\n",
            "43    0.024187\n",
            "99    0.990285\n",
            "39    0.018846\n",
            "97    0.970191\n",
            "Name: co2, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w5kKgRj0Qxsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the 2-layer Neural Network\n",
        "The following function trains the 2-layer neural network. First, we'll write some helper functions."
      ]
    },
    {
      "metadata": {
        "id": "_npQlt3gQxsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "def error_formula(y, output):\n",
        "    return - y*np.log(output) - (1 - y) * np.log(1-output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mp7nxljqQxsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO: Backpropagate the error\n",
        "Now it's your turn to shine. Write the error term. Remember that this is given by the equation $$ (y-\\hat{y}) \\sigma'(x) $$"
      ]
    },
    {
      "metadata": {
        "id": "Ky6XQ3h_Qxsp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write the error term formula\n",
        "def error_term_formula(x, y, output):\n",
        "  \n",
        "    return (y - output)*sigmoid_prime(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbwcBVKJQxss",
        "colab_type": "code",
        "outputId": "63b6f444-900f-44a6-9a0f-f400a44bfe7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Neural Network hyperparameters\n",
        "epochs = 10005\n",
        "learnrate = 0.02\n",
        "\n",
        "# Training function\n",
        "def train_nn(features, targets, epochs, learnrate):\n",
        "    \n",
        "    # Use to same seed to make debugging easier\n",
        "    np.random.seed(42)\n",
        "\n",
        "    n_records, n_features = features.shape\n",
        "    last_loss = None\n",
        "\n",
        "    # Initialize weights\n",
        "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        del_w = np.zeros(weights.shape)\n",
        "        for x, y in zip(features.values, targets):\n",
        "            # Loop through all records, x is the input, y is the target\n",
        "\n",
        "            # Activation of the output unit\n",
        "            #   Notice we multiply the inputs and the weights here \n",
        "            #   rather than storing h as a separate variable \n",
        "            output = sigmoid(np.dot(x, weights))\n",
        "\n",
        "            # The error, the target minus the network output\n",
        "            error = error_formula(y, output)\n",
        "\n",
        "            # The error term\n",
        "            error_term = error_term_formula(x, y, output)\n",
        "\n",
        "            # The gradient descent step, the error times the gradient times the inputs\n",
        "            del_w += error_term * x\n",
        "\n",
        "        # Update the weights here. The learning rate times the \n",
        "        # change in weights, divided by the number of records to average\n",
        "        weights += learnrate * del_w / n_records\n",
        "\n",
        "        # Printing out the mean square error on the training set\n",
        "        if e % (epochs / 10) == 0:\n",
        "            out = sigmoid(np.dot(features, weights))\n",
        "            loss = np.mean((out - targets) ** 2)\n",
        "            print(\"Epoch:\", e)\n",
        "            if last_loss and last_loss < loss:\n",
        "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "            else:\n",
        "                print(\"Train loss: \", loss)\n",
        "            last_loss = loss\n",
        "            print(\"=========\")\n",
        "    print(\"Finished training!\")\n",
        "    return weights\n",
        "    \n",
        "weights = train_nn(features, targets, epochs, learnrate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Train loss:  0.15105682358210995\n",
            "=========\n",
            "Epoch: 2001\n",
            "Train loss:  0.1221528235046718\n",
            "=========\n",
            "Epoch: 4002\n",
            "Train loss:  0.11328533354635922\n",
            "=========\n",
            "Epoch: 6003\n",
            "Train loss:  0.10577754979918183\n",
            "=========\n",
            "Epoch: 8004\n",
            "Train loss:  0.09942292279166798\n",
            "=========\n",
            "Finished training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MrOw_DKEQxsv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculating the Accuracy on the Test Data"
      ]
    },
    {
      "metadata": {
        "id": "FkC3b9PYQxsw",
        "colab_type": "code",
        "outputId": "cf9b4ff7-4512-419e-868a-c4721a0e0f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on test data\n",
        "test_out = sigmoid(np.dot(features_test, weights))\n",
        "predictions = test_out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction accuracy: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}